{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading NetCDF file: [Errno -101] NetCDF: HDF error: b'/Users/ludong/PROGRAM/112-2/Statistics/hw9/sst.mon.mean.trefadj.anom.1880to2018.nc'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load SST anomaly data from the text file\n",
    "sst_data = pd.read_csv('./nino34.long.anom.data.txt', delim_whitespace=True, header=None)\n",
    "sst_data.columns = ['Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "sst_data.set_index('Year', inplace=True)\n",
    "\n",
    "# Load SST data from the NetCDF file using xarray\n",
    "try:\n",
    "    ds = xr.open_dataset('./sst.mon.mean.trefadj.anom.1880to2018.nc')\n",
    "    sst_anomalies = ds['sst'].values  # Assuming 'sst' is the variable name\n",
    "    print(sst_anomalies.shape)\n",
    "except OSError as e:\n",
    "    print(f\"Error reading NetCDF file: {e}\")\n",
    "\n",
    "# Preprocess and label the data\n",
    "def label_event(sst_anomaly):\n",
    "    if sst_anomaly > 0.5:\n",
    "        return 2  # El Ni単o\n",
    "    elif sst_anomaly < -0.5:\n",
    "        return 0  # La Ni単a\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Create labels for each month\n",
    "labels = np.vectorize(label_event)(sst_data.values)\n",
    "\n",
    "# Reshape the data for CNN input\n",
    "X = sst_data.values.reshape(-1, 12, 1)  # One year as one sample with 12 months as features\n",
    "y = labels.reshape(-1, 12)\n",
    "\n",
    "# Custom dataset class\n",
    "class SSTDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = SSTDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(32 * 2, 128)  # 2 comes from the reduced size after conv and pooling layers\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: El Ni単o, La Ni単a, neutral\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model, define loss function and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    # Create a progress bar for the epoch\n",
    "    with tqdm(total=len(dataloader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for inputs, labels in dataloader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels[:, 0])  # labels[:, 0] to match the output shape\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update running loss and progress bar\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1)})\n",
    "            pbar.update(1)\n",
    "            \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels[:, 0]).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model: {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
